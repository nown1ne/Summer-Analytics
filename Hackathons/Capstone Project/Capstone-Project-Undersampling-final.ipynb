{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Taking a look at the dataset and checking imbalances\n"
      ],
      "metadata": {
        "id": "dbOp4oIhHlHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Train_Data.csv')\n",
        "\n",
        "# Take a look at the data\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "print(\"\\n\\nCheck Class imbalance\")\n",
        "class_distribution = data['pred'].value_counts()\n",
        "print(class_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErjMtp1aMoqb",
        "outputId": "4efd2a23-2b39-4383-d503-5fac715e1650"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  pc      ld    m0    m1    m2       m3        m4       m5        m6       m7  \\\n",
            "0  y   83.71  63.0   7.2  52.5  14.0232  130.8300  12.4280  188.8425   8.9520   \n",
            "1  y  108.94  31.5  12.8  84.0  13.2840  128.8350  13.5256  183.0990   8.8520   \n",
            "2  E  169.65   0.0   5.6  73.5  14.5472  128.9295  13.6424  174.4680   8.9800   \n",
            "3  x  122.42  31.5   7.2  63.0  15.0152  119.8575  12.3344  186.8580  10.7208   \n",
            "4  E  125.43  94.5   7.2  42.0  14.4176  135.4290  14.5824  187.8135   9.3088   \n",
            "\n",
            "         m8       m9       m10      m11       m12      m13       m14   ma  \\\n",
            "0  201.1905   9.2896  141.9075  16.0968  150.3390  12.4880  173.1240  m78   \n",
            "1  207.2385   8.4704  154.7805  13.3304  101.0205  12.5096  131.4075  m78   \n",
            "2  190.3125  11.3056  156.7650      NaN  122.5350  11.7136  176.8200  m76   \n",
            "3  193.8195  10.6096  175.7490      NaN  124.8030  13.8424  168.2625  m55   \n",
            "4  203.1540   9.8280  172.7040  14.4720  120.2145      NaN  150.1185  m76   \n",
            "\n",
            "   pred  \n",
            "0     0  \n",
            "1     0  \n",
            "2     1  \n",
            "3     0  \n",
            "4     0  \n",
            "\n",
            "\n",
            "Check Class imbalance\n",
            "0    17711\n",
            "1     4873\n",
            "Name: pred, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking data types to encode other types to int\n"
      ],
      "metadata": {
        "id": "npe0AgCKH6rH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C92x8XiXHrdy",
        "outputId": "0fc6e2c8-9b23-4ff0-abdb-746854ec9c42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pc       object\n",
              "ld      float64\n",
              "m0      float64\n",
              "m1      float64\n",
              "m2      float64\n",
              "m3      float64\n",
              "m4      float64\n",
              "m5      float64\n",
              "m6      float64\n",
              "m7      float64\n",
              "m8      float64\n",
              "m9      float64\n",
              "m10     float64\n",
              "m11     float64\n",
              "m12     float64\n",
              "m13     float64\n",
              "m14     float64\n",
              "ma       object\n",
              "pred      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode categorical columns from string to int\n",
        "categorical_cols = ['pc','ma']\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    data[col] = label_encoder.fit_transform(data[col])"
      ],
      "metadata": {
        "id": "wlrelm0QHwHF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After testing various imputation methods, it was observed that the best result was obtained by dropping the nan values instead\n"
      ],
      "metadata": {
        "id": "gTPQUsx2HZUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute NaN values using KNN imputer\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "nCmgiJUMngZ1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there was a severe class imbalance both over and undersampling was tested.\n",
        "Under sampling provided better results and hence was finalized"
      ],
      "metadata": {
        "id": "2CDe0XLuIBKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('pred', axis=1)\n",
        "y = data['pred']\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have your feature matrix 'X' and corresponding labels 'y'\n",
        "# Create an instance of the RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Perform undersampling on the dataset\n",
        "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
        "\n",
        "# Convert the undersampled data to a DataFrame (optional)\n",
        "data = pd.DataFrame(X_undersampled, columns=X.columns)\n",
        "data['pred'] = y_undersampled\n",
        "\n",
        "\n",
        "print(\"Chekcing cclass distribution after undersampling\")\n",
        "class_distribution = data['pred'].value_counts()\n",
        "print(class_distribution)\n",
        "\n",
        "\n",
        "X = data.drop('pred', axis=1)\n",
        "y = data['pred']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pmoFj_pmsV",
        "outputId": "45b98bc2-54ce-4e3d-ac8b-58f0047b24a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chekcing cclass distribution after undersampling\n",
            "0    2841\n",
            "1    2841\n",
            "Name: pred, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "        RandomForestClassifier(),\n",
        "        LogisticRegression(),\n",
        "        SVC(),\n",
        "        DecisionTreeClassifier(),\n",
        "        KNeighborsClassifier(),\n",
        "        GaussianNB(),\n",
        "        MLPClassifier(),\n",
        "        AdaBoostClassifier(),\n",
        "        GradientBoostingClassifier(),\n",
        "        AdaBoostClassifier(),\n",
        "        BaggingClassifier(),\n",
        "        ExtraTreesClassifier(),\n",
        "        XGBClassifier()\n",
        "    ]\n",
        "\n",
        "f1_scores = []\n",
        "f1_scores_model = []\n",
        "\n",
        "for model in models:\n",
        "      model.fit(X_train, y_train)\n",
        "      y_pred = model.predict(X_test)\n",
        "      print(model)\n",
        "      print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICtlq8lJY5Hs",
        "outputId": "30a1117d-a140-40e8-cd43-535d98ef33c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.55      0.55       579\n",
            "           1       0.53      0.53      0.53       558\n",
            "\n",
            "    accuracy                           0.54      1137\n",
            "   macro avg       0.54      0.54      0.54      1137\n",
            "weighted avg       0.54      0.54      0.54      1137\n",
            "\n",
            "LogisticRegression()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.61      0.59       579\n",
            "           1       0.57      0.52      0.54       558\n",
            "\n",
            "    accuracy                           0.57      1137\n",
            "   macro avg       0.57      0.57      0.57      1137\n",
            "weighted avg       0.57      0.57      0.57      1137\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.59      0.58       579\n",
            "           1       0.56      0.55      0.56       558\n",
            "\n",
            "    accuracy                           0.57      1137\n",
            "   macro avg       0.57      0.57      0.57      1137\n",
            "weighted avg       0.57      0.57      0.57      1137\n",
            "\n",
            "DecisionTreeClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.49      0.49       579\n",
            "           1       0.47      0.47      0.47       558\n",
            "\n",
            "    accuracy                           0.48      1137\n",
            "   macro avg       0.48      0.48      0.48      1137\n",
            "weighted avg       0.48      0.48      0.48      1137\n",
            "\n",
            "KNeighborsClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.52      0.52       579\n",
            "           1       0.51      0.51      0.51       558\n",
            "\n",
            "    accuracy                           0.52      1137\n",
            "   macro avg       0.52      0.52      0.52      1137\n",
            "weighted avg       0.52      0.52      0.52      1137\n",
            "\n",
            "GaussianNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.69      0.61       579\n",
            "           1       0.57      0.43      0.49       558\n",
            "\n",
            "    accuracy                           0.56      1137\n",
            "   macro avg       0.56      0.56      0.55      1137\n",
            "weighted avg       0.56      0.56      0.55      1137\n",
            "\n",
            "MLPClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.10      0.17       579\n",
            "           1       0.50      0.95      0.66       558\n",
            "\n",
            "    accuracy                           0.52      1137\n",
            "   macro avg       0.59      0.53      0.42      1137\n",
            "weighted avg       0.60      0.52      0.41      1137\n",
            "\n",
            "AdaBoostClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.56      0.55       579\n",
            "           1       0.53      0.51      0.52       558\n",
            "\n",
            "    accuracy                           0.54      1137\n",
            "   macro avg       0.54      0.54      0.54      1137\n",
            "weighted avg       0.54      0.54      0.54      1137\n",
            "\n",
            "GradientBoostingClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.55      0.55       579\n",
            "           1       0.53      0.53      0.53       558\n",
            "\n",
            "    accuracy                           0.54      1137\n",
            "   macro avg       0.54      0.54      0.54      1137\n",
            "weighted avg       0.54      0.54      0.54      1137\n",
            "\n",
            "AdaBoostClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.56      0.55       579\n",
            "           1       0.53      0.51      0.52       558\n",
            "\n",
            "    accuracy                           0.54      1137\n",
            "   macro avg       0.54      0.54      0.54      1137\n",
            "weighted avg       0.54      0.54      0.54      1137\n",
            "\n",
            "BaggingClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.63      0.58       579\n",
            "           1       0.53      0.45      0.49       558\n",
            "\n",
            "    accuracy                           0.54      1137\n",
            "   macro avg       0.54      0.54      0.53      1137\n",
            "weighted avg       0.54      0.54      0.53      1137\n",
            "\n",
            "ExtraTreesClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.58      0.56       579\n",
            "           1       0.54      0.52      0.53       558\n",
            "\n",
            "    accuracy                           0.55      1137\n",
            "   macro avg       0.55      0.55      0.55      1137\n",
            "weighted avg       0.55      0.55      0.55      1137\n",
            "\n",
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
            "              predictor=None, random_state=None, ...)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.54      0.54       579\n",
            "           1       0.53      0.53      0.53       558\n",
            "\n",
            "    accuracy                           0.53      1137\n",
            "   macro avg       0.53      0.53      0.53      1137\n",
            "weighted avg       0.53      0.53      0.53      1137\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After checking multiple models in decreasing order of f1-score and accuracy.\n",
        "Decision Tree Classifier consistently peroformed better and hence was finalized"
      ],
      "metadata": {
        "id": "zL3jMdRHIjk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(model)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_FNFgi6F75r",
        "outputId": "408caae6-decb-4b2a-d1a7-804b74c5fff2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier()\n",
            "0.4793315743183817\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.47      0.48       579\n",
            "           1       0.47      0.49      0.48       558\n",
            "\n",
            "    accuracy                           0.48      1137\n",
            "   macro avg       0.48      0.48      0.48      1137\n",
            "weighted avg       0.48      0.48      0.48      1137\n",
            "\n",
            "0.48070175438596496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After deciding on the model its hyperparameters were tuned and tested to maximize accuracy"
      ],
      "metadata": {
        "id": "rp00BgN0Jgou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O-roZmIJbJ3",
        "outputId": "72812e1d-2938-418c-c8d1-be96b8791694"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retesting the model\n",
        "\n",
        "model = DecisionTreeClassifier(criterion=best_params['criterion'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    min_samples_leaf=best_params['min_samples_leaf'],\n",
        "    max_features=best_params['max_features'])\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(model)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5gJsQieJtE1",
        "outputId": "d6f73b78-6cad-4563-f81a-48c960e722a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt',\n",
            "                       min_samples_leaf=2)\n",
            "0.5620052770448549\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       579\n",
            "           1       0.54      0.75      0.63       558\n",
            "\n",
            "    accuracy                           0.56      1137\n",
            "   macro avg       0.58      0.57      0.55      1137\n",
            "weighted avg       0.58      0.56      0.55      1137\n",
            "\n",
            "0.6283582089552239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read and predict for the test data\n"
      ],
      "metadata": {
        "id": "5ZjgSuN9J6nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('Test_Data.csv')\n",
        "test_data = test_data[X_train.columns]"
      ],
      "metadata": {
        "id": "GlfS2rdFF9qK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After testing various imputation methods it was found that median gave the best results"
      ],
      "metadata": {
        "id": "Gh5zzHqQJ0H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the test data\n",
        "test_data['pc'] = test_data['pc'].map(lambda s: label_encoder.transform([s])[0] if s in label_encoder.classes_ else -1)\n",
        "test_data['ma'] = test_data['ma'].map(lambda s: label_encoder.transform([s])[0] if s in label_encoder.classes_ else -1)\n",
        "\n",
        "#Deal with nan values\n",
        "test_data = test_data.fillna(test_data.median())"
      ],
      "metadata": {
        "id": "tqEsDhc9GAKV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing predictions to csv file"
      ],
      "metadata": {
        "id": "EbnSTtO6J-hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(test_data)\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({'pred': y_test_pred})\n",
        "submission = submission.astype(int)\n",
        "# Save the submission to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "DZUU0LF7GCN0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After multiple iterations of the code (as there was randomness involved due to the under sampler) a maximum score of 34.9683 was obtained."
      ],
      "metadata": {
        "id": "y8noX2TCLbGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Thank you for your time and consideration\n",
        "#Peace"
      ],
      "metadata": {
        "id": "3qe2QJB6LzZ_"
      }
    }
  ]
}